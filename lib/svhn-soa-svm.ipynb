{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 5105 on context None\n",
      "Mapped name None to device cuda0: Quadro K6000 (0000:04:00.0)\n",
      "/Tmp/lisa/os_v5/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python \n",
    "\n",
    "'''\n",
    "-Initially make z_to_x and x_to_z fairly shallow networks.  Inject noise?  \n",
    "\n",
    "-Use the fflayer class?  \n",
    "\n",
    "'''\n",
    "import sys\n",
    "\n",
    "sys.setrecursionlimit(100000)\n",
    "sys.path.append(\"/u/lambalex/DeepLearning/undirected_matching\")\n",
    "sys.path.append(\"/u/lambalex/DeepLearning/undirected_matching/lib\")\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from nn_layers import fflayer, param_init_fflayer, param_init_convlayer, convlayer\n",
    "from utils import init_tparams, join2, srng, dropout, inverse_sigmoid, join3, merge_images\n",
    "from loss import accuracy, crossent, lsgan_loss, wgan_loss, improvement_loss\n",
    "import lasagne\n",
    "import numpy as np\n",
    "import numpy.random as rng\n",
    "import gzip\n",
    "import cPickle as pickle\n",
    "import random\n",
    "from viz import plot_images\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "\n",
    "import os\n",
    "slurm_name = os.environ[\"SLURM_JOB_ID\"]\n",
    "\n",
    "class ConsiderConstant(theano.compile.ViewOp):\n",
    "    def grad(self, args, g_outs):\n",
    "        return [T.zeros_like(g_out) for g_out in g_outs]\n",
    "\n",
    "consider_constant = ConsiderConstant()\n",
    "\n",
    "\n",
    "\n",
    "def init_gparams(p):\n",
    "\n",
    "    p = param_init_fflayer(options={},params=p,prefix='z_x_1',nin=nl*2,nout=512*4*4,ortho=False,batch_norm=True)\n",
    "\n",
    "    p = param_init_convlayer(options={},params=p,prefix='z_x_2',nin=512,nout=256,kernel_len=5,batch_norm=True)\n",
    "    p = param_init_convlayer(options={},params=p,prefix='z_x_3',nin=256*1,nout=128,kernel_len=5,batch_norm=True)\n",
    "    p = param_init_convlayer(options={},params=p,prefix='z_x_4',nin=128*1,nout=3,kernel_len=5,batch_norm=False)\n",
    "\n",
    "    p = param_init_convlayer(options={},params=p,prefix='x_z_1',nin=3,nout=32,kernel_len=5,batch_norm=True)\n",
    "    p = param_init_convlayer(options={},params=p,prefix='x_z_2',nin=32,nout=64,kernel_len=5,batch_norm=True)\n",
    "    p = param_init_convlayer(options={},params=p,prefix='x_z_3',nin=64,nout=128,kernel_len=5,batch_norm=True)\n",
    "    p = param_init_convlayer(options={},params=p,prefix='x_z_4',nin=128,nout=256,kernel_len=5,batch_norm=True)\n",
    "    p = param_init_convlayer(options={},params=p,prefix='x_z_5',nin=256,nout=512,kernel_len=5,batch_norm=True)\n",
    "\n",
    "    p = param_init_fflayer(options={},params=p,prefix='x_z_fc1',nin=512*4*4,nout=1024,ortho=False,batch_norm=True)\n",
    "    p = param_init_fflayer(options={},params=p,prefix='x_z_fc2',nin=1024,nout=1024,ortho=False,batch_norm=True)\n",
    "\n",
    "    p = param_init_fflayer(options={},params=p,prefix='x_z_mu',nin=1024,nout=nl,ortho=False,batch_norm=False)\n",
    "    p = param_init_fflayer(options={},params=p,prefix='x_z_sigma',nin=1024,nout=nl,ortho=False,batch_norm=False)\n",
    "\n",
    "    return init_tparams(p)\n",
    "\n",
    "def init_cparams(p):\n",
    "\n",
    "    p = param_init_fflayer(options={},params=p,prefix='c_1',nin=nl+512*4*4,nout=512,ortho=False,batch_norm=True)\n",
    "    print \"mlp on top, 512 dim\"\n",
    "    p = param_init_fflayer(options={},params=p,prefix='c_2',nin=512,nout=512,ortho=False,batch_norm=True)\n",
    "    p = param_init_fflayer(options={},params=p,prefix='c_3',nin=512,nout=10,ortho=False,batch_norm=False)\n",
    "\n",
    "    return init_tparams(p)\n",
    "\n",
    "def init_dparams(p):\n",
    "\n",
    "    print \"NOT trying batch norm in the discriminator part that sees x!\"\n",
    "    p = param_init_convlayer(options={},params=p,prefix='DC_1',nin=3,nout=32,kernel_len=5,batch_norm=False)\n",
    "    p = param_init_convlayer(options={},params=p,prefix='DC_2',nin=32,nout=64,kernel_len=5,batch_norm=False)\n",
    "    p = param_init_convlayer(options={},params=p,prefix='DC_3',nin=64,nout=128,kernel_len=5,batch_norm=False)\n",
    "    p = param_init_convlayer(options={},params=p,prefix='DC_4',nin=128,nout=256,kernel_len=5,batch_norm=False)\n",
    "    p = param_init_convlayer(options={},params=p,prefix='DC_5',nin=256,nout=512,kernel_len=5,batch_norm=False)\n",
    "\n",
    "    p = param_init_fflayer(options={},params=p,prefix='D_1',nin=nl+512*4*4,nout=nfd,ortho=False,batch_norm=False)\n",
    "    p = param_init_fflayer(options={},params=p,prefix='D_2',nin=nfd,nout=nfd,ortho=False,batch_norm=False)\n",
    "    p = param_init_fflayer(options={},params=p,prefix='D_3',nin=nfd,nout=nfd,ortho=False,batch_norm=False)\n",
    "\n",
    "    p = param_init_fflayer(options={},params=p,prefix='D_o_1',nin=nfd,nout=1,ortho=False,batch_norm=False)\n",
    "    p = param_init_fflayer(options={},params=p,prefix='D_o_2',nin=nfd,nout=1,ortho=False,batch_norm=False)\n",
    "    p = param_init_fflayer(options={},params=p,prefix='D_o_3',nin=nfd,nout=1,ortho=False,batch_norm=False)\n",
    "\n",
    "    p = param_init_convlayer(options={},params=p,prefix='D_o_4',nin=128,nout=1,kernel_len=5,batch_norm=False)\n",
    "    p = param_init_convlayer(options={},params=p,prefix='D_o_5',nin=256,nout=1,kernel_len=5,batch_norm=False)\n",
    "    p = param_init_convlayer(options={},params=p,prefix='D_o_6',nin=512,nout=1,kernel_len=5,batch_norm=False)\n",
    "\n",
    "    return init_tparams(p)\n",
    "\n",
    "\n",
    "def z_to_x(p,z):\n",
    "\n",
    "    print \"no extra noise input\"\n",
    "    z_inp = join2(z, 0.0*srng.normal(size=z.shape))\n",
    "\n",
    "    d0 = fflayer(tparams=p,state_below=z_inp,options={},prefix='z_x_1',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)')\n",
    "\n",
    "    d0 = d0.reshape((64,512,4,4))\n",
    "\n",
    "    d1 = convlayer(tparams=p,state_below=d0,options={},prefix='z_x_2',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)',stride=-2)\n",
    "\n",
    "    d2 = convlayer(tparams=p,state_below=d1,options={},prefix='z_x_3',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)',stride=-2)\n",
    "\n",
    "    d3 = convlayer(tparams=p,state_below=d2,options={},prefix='z_x_4',activ='lambda x: x',stride=-2)\n",
    "\n",
    "    x_new = d3.flatten(2)\n",
    "\n",
    "    return x_new\n",
    "\n",
    "def x_to_z(p,x):\n",
    "\n",
    "    e1 = convlayer(tparams=p,state_below=x.reshape((64,3,32,32)),options={},prefix='x_z_1',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)',stride=1)\n",
    "\n",
    "    e2 = convlayer(tparams=p,state_below=e1,options={},prefix='x_z_2',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)',stride=2)\n",
    "\n",
    "    e3 = convlayer(tparams=p,state_below=e2,options={},prefix='x_z_3',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)',stride=1)\n",
    "\n",
    "    e4 = convlayer(tparams=p,state_below=e3,options={},prefix='x_z_4',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)',stride=2)\n",
    "\n",
    "    e5 = convlayer(tparams=p,state_below=e4,options={},prefix='x_z_5',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)',stride=2)\n",
    "\n",
    "    eo = e5\n",
    "    eo = eo.flatten(2)\n",
    "\n",
    "    encoder_features = eo\n",
    "\n",
    "    h1 = fflayer(tparams=p,state_below=eo,options={},prefix='x_z_fc1',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)')\n",
    "    h2 = fflayer(tparams=p,state_below=h1,options={},prefix='x_z_fc2',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)')\n",
    "\n",
    "    sigma = fflayer(tparams=p,state_below=h2,options={},prefix='x_z_mu',activ='lambda x: x')\n",
    "    mu = fflayer(tparams=p,state_below=h2,options={},prefix='x_z_sigma',activ='lambda x: x')\n",
    "\n",
    "    eps = srng.normal(size=sigma.shape)\n",
    "\n",
    "    z_new = eps*T.nnet.sigmoid(sigma) + mu\n",
    "    print \"turned on injected noise in x->z connection\"\n",
    "\n",
    "    z_new = (z_new - T.mean(z_new, axis=0, keepdims=True)) / (0.001 + T.std(z_new, axis=0, keepdims=True))\n",
    "\n",
    "    return z_new,encoder_features\n",
    "\n",
    "def classifier(p,z,true_y):\n",
    "\n",
    "    print \"turning off gradients from classifier\"\n",
    "    z = consider_constant(z)\n",
    "\n",
    "    h1 = fflayer(tparams=p,state_below=z,options={},prefix='c_1',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)')\n",
    "\n",
    "    h2 = fflayer(tparams=p,state_below=h1,options={},prefix='c_2',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)')\n",
    "\n",
    "    y_est = fflayer(tparams=p,state_below=h2,options={},prefix='c_3',activ='lambda x: x')\n",
    "\n",
    "    y_est = T.nnet.softmax(y_est)\n",
    "\n",
    "    acc = accuracy(y_est,true_y)\n",
    "    loss = crossent(y_est,true_y)\n",
    "\n",
    "    return loss,acc\n",
    "\n",
    "def discriminator(p,x,z):\n",
    "\n",
    "    dc_1 = convlayer(tparams=p,state_below=x.reshape((64,3,32,32)),options={},prefix='DC_1',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)',stride=1)\n",
    "\n",
    "    dc_2 = convlayer(tparams=p,state_below=dc_1,options={},prefix='DC_2',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)',stride=2)\n",
    "\n",
    "    dc_3 = convlayer(tparams=p,state_below=dc_2,options={},prefix='DC_3',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)',stride=1)\n",
    "\n",
    "    dc_4 = convlayer(tparams=p,state_below=dc_3,options={},prefix='DC_4',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)',stride=2)\n",
    "\n",
    "    dc_5 = convlayer(tparams=p,state_below=dc_4,options={},prefix='DC_5',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)',stride=2)\n",
    "\n",
    "    inp = join2(z,dc_5.flatten(2))\n",
    "\n",
    "    h1 = fflayer(tparams=p,state_below=inp,options={},prefix='D_1',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)',mean_ln=False)\n",
    "\n",
    "    h2 = fflayer(tparams=p,state_below=h1,options={},prefix='D_2',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)', mean_ln=False)\n",
    "\n",
    "    h3 = fflayer(tparams=p,state_below=h2,options={},prefix='D_3',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)', mean_ln=False)\n",
    "\n",
    "    D1 = fflayer(tparams=p,state_below=h1,options={},prefix='D_o_1',activ='lambda x: x')\n",
    "    D2 = fflayer(tparams=p,state_below=h2,options={},prefix='D_o_2',activ='lambda x: x')\n",
    "    D3 = fflayer(tparams=p,state_below=h3,options={},prefix='D_o_3',activ='lambda x: x')\n",
    "\n",
    "    D4 = convlayer(tparams=p,state_below=dc_3,options={},prefix='D_o_4',activ='lambda x: x',stride=2)\n",
    "    D5 = convlayer(tparams=p,state_below=dc_4,options={},prefix='D_o_5',activ='lambda x: x',stride=2)\n",
    "    D6 = convlayer(tparams=p,state_below=dc_5,options={},prefix='D_o_6',activ='lambda x: x',stride=2)\n",
    "\n",
    "    print \"special thing in D\"\n",
    "    return [D1,D2,D3,D4,D5,D6], [h3,dc_5.flatten(2)]\n",
    "\n",
    "def p_chain(p, z, num_iterations):\n",
    "    zlst = [z]\n",
    "    xlst = []\n",
    "\n",
    "    if num_iterations == 1:\n",
    "        \n",
    "        new_x = z_to_x(p, zlst[-1])\n",
    "        xlst.append(new_x)\n",
    "        #new_z = x_to_z(p, xlst[-1])\n",
    "        #zlst.append(new_z)\n",
    "\n",
    "    elif num_iterations == 3:  \n",
    "\n",
    "        new_x = z_to_x(p, zlst[-1])\n",
    "        xlst.append(new_x)\n",
    "        new_z,_ = x_to_z(p, consider_constant(xlst[-1]))\n",
    "        zlst.append(new_z)\n",
    "\n",
    "        new_x = z_to_x(p, zlst[-1])\n",
    "        xlst.append(new_x)\n",
    "        new_z,_ = x_to_z(p, consider_constant(xlst[-1]))\n",
    "        zlst.append(new_z)\n",
    "\n",
    "        new_x = z_to_x(p, zlst[-1])\n",
    "        xlst.append(new_x)\n",
    "\n",
    "    else:\n",
    "\n",
    "        for inds in range(0,num_iterations):\n",
    "            new_x = z_to_x(p, zlst[-1])\n",
    "            xlst.append(new_x)\n",
    "            new_z,_ = x_to_z(p, xlst[-1])\n",
    "            zlst.append(new_z)\n",
    "\n",
    "\n",
    "    for j in range(len(xlst)):\n",
    "        xlst[j] = T.nnet.sigmoid(xlst[j])\n",
    "\n",
    "    return xlst, zlst\n",
    "\n",
    "def onestep_z_to_x(p,z):\n",
    "    x = T.nnet.sigmoid(z_to_x(p, z))\n",
    "    return x\n",
    "\n",
    "def onestep_x_to_z(p,x):\n",
    "    new_z,_ = x_to_z(p, inverse_sigmoid(x))\n",
    "    return new_z\n",
    "\n",
    "def q_chain(p,x,num_iterations):\n",
    "\n",
    "    xlst = [x]\n",
    "    zlst = []\n",
    "    new_z,encoder_features = x_to_z(p, inverse_sigmoid(xlst[-1]))\n",
    "    zlst.append(new_z)\n",
    "\n",
    "    return xlst, zlst,encoder_features\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "print \"a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num latent 128\n",
      "num steps 3\n",
      "latent sparse False\n",
      "improvement loss weight 0.0\n",
      "num labeled examples used 50000\n",
      "dataset svhn\n",
      "num train examples 604388\n",
      "num test examples 26032\n",
      "NOT trying batch norm in the discriminator part that sees x!\n",
      "mlp on top, 512 dim\n",
      "no extra noise input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Quadro K6000 (CNMeM is disabled, cuDNN 5105)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "special thing in D\n",
      "single disc\n",
      "special thing in D\n",
      "turning off gradients from classifier\n",
      "not using improvement objective\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n"
     ]
    }
   ],
   "source": [
    "nl = 128\n",
    "print \"num latent\", nl\n",
    "#128 works for nl\n",
    "nfg = 512\n",
    "nfd = 512\n",
    "\n",
    "\n",
    "#3\n",
    "num_steps = 3\n",
    "print \"num steps\", num_steps\n",
    "\n",
    "latent_sparse = False\n",
    "print \"latent sparse\", latent_sparse\n",
    "\n",
    "improvement_loss_weight = 0.0\n",
    "print \"improvement loss weight\", improvement_loss_weight\n",
    "\n",
    "num_labeled_examples_use = 50000\n",
    "print \"num labeled examples used\",num_labeled_examples_use\n",
    "\n",
    "#dataset = \"mnist\"\n",
    "#dataset = \"anime\"\n",
    "dataset = \"svhn\"\n",
    "print \"dataset\", dataset\n",
    "\n",
    "if dataset == \"mnist\":\n",
    "    mn = gzip.open(\"/u/lambalex/data/mnist/mnist.pkl.gz\")\n",
    "\n",
    "    train, valid, test = pickle.load(mn)\n",
    "\n",
    "    trainx,trainy = train\n",
    "\n",
    "\n",
    "    #newtx = trainx[(trainy<2) | (trainy>8)]\n",
    "    #newty = trainy[(trainy<2) | (trainy>8)]\n",
    "    #trainx = newtx\n",
    "    #trainy = newty\n",
    "\n",
    "    validx,validy = valid\n",
    "    testx, testy = test\n",
    "\n",
    "    num_examples = trainx.shape[0]\n",
    "\n",
    "    m = 784\n",
    "\n",
    "elif dataset == \"anime\":\n",
    "    from load_file import FileData, normalize, denormalize\n",
    "\n",
    "    loc = \"/u/lambalex/DeepLearning/animefaces/datafaces/danbooru-faces/\"\n",
    "\n",
    "    animeData = FileData(loc, 32, 64)\n",
    "\n",
    "    m = 32*32*3\n",
    "\n",
    "elif dataset == \"svhn\":\n",
    "\n",
    "    from load_svhn import SvhnData\n",
    "    from load_file import normalize, denormalize\n",
    "\n",
    "    svhnData = SvhnData()\n",
    "\n",
    "    num_examples = 50000\n",
    "\n",
    "\n",
    "\n",
    "gparams = init_gparams({})\n",
    "dparams = init_dparams({})\n",
    "cparams = init_cparams({})\n",
    "\n",
    "z_in = T.matrix('z_in')\n",
    "x_in = T.matrix()\n",
    "true_y = T.ivector('true_y')\n",
    "\n",
    "p_lst_x,p_lst_z = p_chain(gparams, z_in, num_steps)\n",
    "\n",
    "q_lst_x,q_lst_z,encoder_features = q_chain(gparams, x_in, num_steps)\n",
    "\n",
    "p_lst_x_long,p_lst_z_long = p_chain(gparams, z_in, 19)\n",
    "\n",
    "z_inf = q_lst_z[-1]\n",
    "\n",
    "D_p_lst_1,_ = discriminator(dparams, p_lst_x[-1], p_lst_z[-1])\n",
    "\n",
    "if False:\n",
    "    D_p_lst_2,_ = discriminator(dparams, p_lst_x[-2], p_lst_z[-2])\n",
    "    D_p_lst = D_p_lst_1 + D_p_lst_2\n",
    "    print \"double disc\"\n",
    "else:\n",
    "    D_p_lst = D_p_lst_1\n",
    "    print \"single disc\"\n",
    "\n",
    "D_q_lst,D_feat_q = discriminator(dparams, q_lst_x[-1], q_lst_z[-1])\n",
    "\n",
    "closs,cacc = classifier(cparams,join2(z_inf,encoder_features),true_y)\n",
    "\n",
    "dloss, gloss = lsgan_loss(D_q_lst, D_p_lst)\n",
    "\n",
    "print \"not using improvement objective\"\n",
    "#improvement_objective = improvement_loss_weight * improvement_loss(D_p_lst_1, D_p_lst_2)\n",
    "#gloss += improvement_objective\n",
    "\n",
    "dupdates = lasagne.updates.rmsprop(dloss, dparams.values(),0.0001)\n",
    "gloss_grads = T.grad(gloss, gparams.values(), disconnected_inputs='ignore')\n",
    "gupdates = lasagne.updates.rmsprop(gloss_grads, gparams.values(),0.0001)\n",
    "\n",
    "gcupdates = lasagne.updates.rmsprop(gloss + closs, gparams.values() + cparams.values(),0.0001)\n",
    "dcupdates = lasagne.updates.rmsprop(dloss + closs, dparams.values() + cparams.values(),0.0001)\n",
    "\n",
    "dgupdates = dupdates.copy()\n",
    "dgupdates.update(gupdates)\n",
    "\n",
    "dgcupdates = dcupdates.copy()\n",
    "dgcupdates.update(gcupdates)\n",
    "\n",
    "train_disc_gen_classifier = theano.function(inputs = [x_in, z_in,true_y], outputs=[dloss,p_lst_x[-1],p_lst_z[-1],closs,cacc], updates=dgcupdates,on_unused_input='ignore')\n",
    "\n",
    "train_disc_gen = theano.function(inputs = [x_in, z_in], outputs=[dloss,p_lst_x[-1],p_lst_z[-1]], updates=dgupdates,on_unused_input='ignore')\n",
    "\n",
    "train_disc_gen_faster = theano.function(inputs = [x_in, z_in], outputs=dloss, updates=dgupdates,on_unused_input='ignore')\n",
    "\n",
    "test_classifier = theano.function(inputs = [x_in,true_y], outputs=[closs,cacc],on_unused_input='ignore')\n",
    "\n",
    "get_zinf = theano.function([x_in], outputs=z_inf)\n",
    "#get_dfeat = theano.function([x_in], outputs=D_feat_q)\n",
    "\n",
    "#get_pchain = theano.function([z_in], outputs = p_lst_x_long)\n",
    "\n",
    "x_in = T.matrix()\n",
    "\n",
    "func_z_to_x = theano.function([z_in], outputs = onestep_z_to_x(gparams, z_in))\n",
    "func_x_to_z = theano.function([x_in], outputs = onestep_x_to_z(gparams, x_in))\n",
    "\n",
    "z_out_p = rng.normal(size=(64,nl)).astype('float32')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turned on injected noise in x->z connection\n",
      "special thing in D\n"
     ]
    }
   ],
   "source": [
    "input_x = T.matrix('x')\n",
    "\n",
    "z_inf,z_feat = x_to_z(gparams, inverse_sigmoid(input_x))\n",
    "\n",
    "d_val, d_feat = discriminator(dparams, input_x, z_inf)\n",
    "\n",
    "#z_feat, d_feat[1]\n",
    "get_dz = theano.function([input_x], outputs = [d_feat[0],d_feat[1]])\n",
    "\n",
    "get_z = func_x_to_z\n",
    "\n",
    "\n",
    "#rec = theano.function([input_x], outputs = [T.nnet.sigmoid(z_to_x(gparams,x_to_z(gparams,inverse_sigmoid(input_x))[0]))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get_dz(x)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zstats = []\n",
    "dzstats = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for iteration in range(0,500000):\n",
    "\n",
    "    z_in2 = rng.normal(size=(64,nl)).astype('float32')\n",
    "\n",
    "    if latent_sparse:\n",
    "        z_in2[:,128:] *= 0.0\n",
    "\n",
    "    r = random.randint(0,num_examples-64)\n",
    "\n",
    "    if dataset == \"mnist\":\n",
    "        x_in = trainx[r:r+64]\n",
    "        y_in = trainy[r:r+64]\n",
    "\n",
    "        x_in = x_in.reshape((64,1,28,28))\n",
    "\n",
    "        x_in = np.repeat(x_in,3,axis=(1))\n",
    "        x_in = np.lib.pad(x_in,((0,0),(0,0),(2,2),(2,2)),'constant',constant_values=(0))\n",
    "\n",
    "        x_in = x_in.reshape((64,32*32*3))\n",
    "    elif dataset == \"anime\":\n",
    "        x_in = normalize(animeData.getBatch()).reshape((64,32*32*3))\n",
    "\n",
    "    elif dataset == \"svhn\":\n",
    "\n",
    "        #just do a quick update using the whole thing.  \n",
    "\n",
    "        ind = random.randint(0,574168-64)\n",
    "        svhn_batch = svhnData.getBatch(mb_size=64,index=ind,segment=\"train\")\n",
    "        x_in2 = normalize(svhn_batch['x']).reshape((64,32*32*3))\n",
    "        train_disc_gen_faster(x_in2,z_in2)\n",
    "\n",
    "        if random.uniform(0,1) < 0.1:\n",
    "            ind = random.randint(0,num_labeled_examples_use)\n",
    "            svhn_batch = svhnData.getBatch(mb_size=64,index=ind,segment=\"hard_train\")\n",
    "            x_in2 = normalize(svhn_batch['x']).reshape((64,32*32*3))\n",
    "            y_in = svhn_batch['y']\n",
    "\n",
    "            dloss,gen_x,z_out_p,closs,cacc = train_disc_gen_classifier(x_in2,z_in2,y_in)\n",
    "\n",
    "            print \"i\", iteration, \"dloss\", dloss, \"gen_x mean\", gen_x.mean(), \"closs\", closs, \"cacc\", cacc\n",
    "\n",
    "    if iteration % 1000 == 0:\n",
    "\n",
    "        if dataset == \"svhn\":\n",
    "            acclst = []\n",
    "            for ind in range(0,26032-128,64):\n",
    "            #ind = random.randint(0,26032-64)\n",
    "                testbatch = svhnData.getBatch(index=ind,mb_size=64,segment=\"test\")\n",
    "                closs,cacc = test_classifier(normalize(testbatch['x']).reshape((64,32*32*3)),testbatch['y'])\n",
    "                acclst.append(cacc)\n",
    "\n",
    "            print \"all test data\"\n",
    "            print \"test accuracy\", sum(acclst)*1.0/len(acclst)\n",
    "\n",
    "        #######plot_images(gen_x, \"plots/\" + slurm_name + \"_gen.png\")\n",
    "        plot_images(func_z_to_x(func_x_to_z(x_in2)).reshape((64,32*32*3)), \"plots/\" + slurm_name + \"_rec.png\")\n",
    "\n",
    "\n",
    "\n",
    "        dhlst = []\n",
    "        dzhlst = []\n",
    "        ylst = []\n",
    "        t0 = time.time()\n",
    "\n",
    "        dhlst_test = []\n",
    "        dzhlst_test = []\n",
    "        ylst_test = []\n",
    "\n",
    "        print \"all train set\"\n",
    "#         print \"only using eoz features\"\n",
    "\n",
    "        for ind in range(0,1000,64):\n",
    "\n",
    "            svhn_batch = svhnData.getBatch(mb_size=64,index=ind,segment=\"train\")\n",
    "            x = normalize(svhn_batch['x']).reshape((64,3*32*32))\n",
    "            y = svhn_batch['y']\n",
    "\n",
    "            zstuff = get_z(x)\n",
    "            dzstuff = get_dz(x)\n",
    "\n",
    "            #print zstuff[0].shape, zstuff[1].shape, zstuff[2].shape\n",
    "            dhlst.append(zstuff)\n",
    "            dzhlst.append(np.concatenate(dzstuff,axis=1))\n",
    "            \n",
    "            ylst.append(y)\n",
    "\n",
    "        for ind in range(0,20000,64):\n",
    "            svhn_batch = svhnData.getBatch(mb_size=64,index=ind,segment=\"test\")\n",
    "            x = normalize(svhn_batch['x']).reshape((64,3*32*32))\n",
    "            y = svhn_batch['y']\n",
    "            zstuff = get_z(x)\n",
    "            dzstuff = get_dz(x)\n",
    "            \n",
    "            dhlst_test.append(zstuff)\n",
    "            dzhlst_test.append(np.concatenate(dzstuff,axis=1))\n",
    "            \n",
    "            ylst_test.append(y)\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "        ##### DDDDDDZZZZZZZ\n",
    "        X_train = np.vstack(dzhlst)\n",
    "        Y_train = np.vstack(ylst).flatten()\n",
    "\n",
    "        X_test = np.vstack(dzhlst_test)\n",
    "        Y_test = np.vstack(ylst_test).flatten()\n",
    "\n",
    "        \n",
    "        C = 1.0\n",
    "        print \"DDDDDDZZZZZZZ starting training!\", \"using svm linear\", \"C\", C, \"squared hinge\"\n",
    "\n",
    "        model = svm.LinearSVC(C=C,loss='squared_hinge')\n",
    "\n",
    "        model.fit(X_train, Y_train)\n",
    "\n",
    "        print \"predicting held out\"\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        testacc = np.mean(np.equal(Y_test, y_pred))\n",
    "        #print \"held out accuracy\", testacc\n",
    "\n",
    "        y_pred = model.predict(X_train)\n",
    "\n",
    "        trainacc = np.mean(np.equal(Y_train, y_pred))\n",
    "        #print \"training accuracy\", trainacc\n",
    "\n",
    "        #print time.time() - t0, \"total time to run\"\n",
    "        \n",
    "        print \"###d#\",iteration, \"testacc\", testacc, \"trainacc\", trainacc\n",
    "        zstats.append([testacc, trainacc])\n",
    "        \n",
    "        \n",
    "        \n",
    "        ##### ZZZZZZZ\n",
    "        \n",
    "        X_train = np.vstack(zhlst)\n",
    "        Y_train = np.vstack(ylst).flatten()\n",
    "\n",
    "        X_test = np.vstack(zhlst_test)\n",
    "        Y_test = np.vstack(ylst_test).flatten()\n",
    "\n",
    "\n",
    "        C = 1.0\n",
    "        print \"ZZZZZZ starting training!\", \"using svm linear\", \"C\", C, \"squared hinge\"\n",
    "\n",
    "        model = svm.LinearSVC(C=C,loss='squared_hinge')\n",
    "\n",
    "        model.fit(X_train, Y_train)\n",
    "\n",
    "        print \"predicting held out\"\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        testacc = np.mean(np.equal(Y_test, y_pred))\n",
    "        #print \"held out accuracy\", testacc\n",
    "\n",
    "        y_pred = model.predict(X_train)\n",
    "\n",
    "        trainacc = np.mean(np.equal(Y_train, y_pred))\n",
    "        #print \"training accuracy\", trainacc\n",
    "\n",
    "        \n",
    "        print \"###dz#\",iteration, \"testacc\", testacc, \"trainacc\", trainacc\n",
    "        dzstats.append([testacc, trainacc])\n",
    "        \n",
    "        statsname = \"stats.pkl\"\n",
    "        pickle.dump([zstats,dzstats], open(statsname, \"w\", 0))\n",
    "        print \"wrote\", statsname, time.time() - t0, \"total time to run\"\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(np.asarray(dzstats)[:,1], label=\"Disc Train\", linestyle='--')\n",
    "\n",
    "plt.plot(np.asarray(dzstats)[:,0], label=\"Disc Test\", linestyle='--')\n",
    "\n",
    "# plt.plot(np.asarray(zstats)[:,1], label=\"Train\", linestyle='-')\n",
    "# plt.plot(np.asarray(zstats)[:,0], label=\"Test\", linestyle='-')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
