{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 5105 on context None\n",
      "Mapped name None to device cuda0: Quadro K6000 (0000:03:00.0)\n",
      "/Tmp/lisa/os_v5/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python \n",
    "\n",
    "'''\n",
    "-Initially make z_to_x and x_to_z fairly shallow networks.  Inject noise?  \n",
    "\n",
    "-Use the fflayer class?  \n",
    "\n",
    "'''\n",
    "import sys\n",
    "\n",
    "sys.setrecursionlimit(100000)\n",
    "sys.path.append(\"/u/lambalex/DeepLearning/undirected_matching\")\n",
    "sys.path.append(\"/u/lambalex/DeepLearning/undirected_matching/lib\")\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from nn_layers import fflayer, param_init_fflayer, param_init_convlayer, convlayer\n",
    "from utils import init_tparams, join2, srng, dropout, inverse_sigmoid, join3, merge_images\n",
    "from loss import accuracy, crossent, lsgan_loss, wgan_loss, improvement_loss\n",
    "import lasagne\n",
    "import numpy as np\n",
    "import numpy.random as rng\n",
    "import gzip\n",
    "import cPickle as pickle\n",
    "import random\n",
    "from viz import plot_images\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "\n",
    "import os\n",
    "slurm_name = os.environ[\"SLURM_JOB_ID\"]\n",
    "\n",
    "class ConsiderConstant(theano.compile.ViewOp):\n",
    "    def grad(self, args, g_outs):\n",
    "        return [T.zeros_like(g_out) for g_out in g_outs]\n",
    "\n",
    "consider_constant = ConsiderConstant()\n",
    "\n",
    "\n",
    "\n",
    "def init_gparams(p):\n",
    "\n",
    "    p = param_init_fflayer(options={},params=p,prefix='z_x_1',nin=nl*2,nout=512*4*4,ortho=False,batch_norm=True)\n",
    "\n",
    "    p = param_init_convlayer(options={},params=p,prefix='z_x_2',nin=512,nout=256,kernel_len=5,batch_norm=True)\n",
    "    p = param_init_convlayer(options={},params=p,prefix='z_x_3',nin=256*1,nout=128,kernel_len=5,batch_norm=True)\n",
    "    p = param_init_convlayer(options={},params=p,prefix='z_x_4',nin=128*1,nout=3,kernel_len=5,batch_norm=False)\n",
    "\n",
    "    p = param_init_convlayer(options={},params=p,prefix='x_z_1',nin=3,nout=32,kernel_len=5,batch_norm=True)\n",
    "    p = param_init_convlayer(options={},params=p,prefix='x_z_2',nin=32,nout=64,kernel_len=5,batch_norm=True)\n",
    "    p = param_init_convlayer(options={},params=p,prefix='x_z_3',nin=64,nout=128,kernel_len=5,batch_norm=True)\n",
    "    p = param_init_convlayer(options={},params=p,prefix='x_z_4',nin=128,nout=256,kernel_len=5,batch_norm=True)\n",
    "    p = param_init_convlayer(options={},params=p,prefix='x_z_5',nin=256,nout=512,kernel_len=5,batch_norm=True)\n",
    "\n",
    "    p = param_init_fflayer(options={},params=p,prefix='x_z_fc1',nin=512*4*4,nout=1024,ortho=False,batch_norm=True)\n",
    "    p = param_init_fflayer(options={},params=p,prefix='x_z_fc2',nin=1024,nout=1024,ortho=False,batch_norm=True)\n",
    "\n",
    "    p = param_init_fflayer(options={},params=p,prefix='x_z_mu',nin=1024,nout=nl,ortho=False,batch_norm=False)\n",
    "    p = param_init_fflayer(options={},params=p,prefix='x_z_sigma',nin=1024,nout=nl,ortho=False,batch_norm=False)\n",
    "\n",
    "    return init_tparams(p)\n",
    "\n",
    "def init_cparams(p):\n",
    "\n",
    "    p = param_init_fflayer(options={},params=p,prefix='c_1',nin=nl+512*4*4,nout=512,ortho=False,batch_norm=True)\n",
    "    print \"mlp on top, 512 dim\"\n",
    "    p = param_init_fflayer(options={},params=p,prefix='c_2',nin=512,nout=512,ortho=False,batch_norm=True)\n",
    "    p = param_init_fflayer(options={},params=p,prefix='c_3',nin=512,nout=10,ortho=False,batch_norm=False)\n",
    "\n",
    "    return init_tparams(p)\n",
    "\n",
    "def init_dparams(p):\n",
    "\n",
    "    print \"NOT trying batch norm in the discriminator part that sees x!\"\n",
    "    p = param_init_convlayer(options={},params=p,prefix='DC_1',nin=3,nout=32,kernel_len=5,batch_norm=False)\n",
    "    p = param_init_convlayer(options={},params=p,prefix='DC_2',nin=32,nout=64,kernel_len=5,batch_norm=False)\n",
    "    p = param_init_convlayer(options={},params=p,prefix='DC_3',nin=64,nout=128,kernel_len=5,batch_norm=False)\n",
    "    p = param_init_convlayer(options={},params=p,prefix='DC_4',nin=128,nout=256,kernel_len=5,batch_norm=False)\n",
    "    p = param_init_convlayer(options={},params=p,prefix='DC_5',nin=256,nout=512,kernel_len=5,batch_norm=False)\n",
    "\n",
    "    p = param_init_fflayer(options={},params=p,prefix='D_1',nin=nl+512*4*4,nout=nfd,ortho=False,batch_norm=False)\n",
    "    p = param_init_fflayer(options={},params=p,prefix='D_2',nin=nfd,nout=nfd,ortho=False,batch_norm=False)\n",
    "    p = param_init_fflayer(options={},params=p,prefix='D_3',nin=nfd,nout=nfd,ortho=False,batch_norm=False)\n",
    "\n",
    "    p = param_init_fflayer(options={},params=p,prefix='D_o_1',nin=nfd,nout=1,ortho=False,batch_norm=False)\n",
    "    p = param_init_fflayer(options={},params=p,prefix='D_o_2',nin=nfd,nout=1,ortho=False,batch_norm=False)\n",
    "    p = param_init_fflayer(options={},params=p,prefix='D_o_3',nin=nfd,nout=1,ortho=False,batch_norm=False)\n",
    "\n",
    "    p = param_init_convlayer(options={},params=p,prefix='D_o_4',nin=128,nout=1,kernel_len=5,batch_norm=False)\n",
    "    p = param_init_convlayer(options={},params=p,prefix='D_o_5',nin=256,nout=1,kernel_len=5,batch_norm=False)\n",
    "    p = param_init_convlayer(options={},params=p,prefix='D_o_6',nin=512,nout=1,kernel_len=5,batch_norm=False)\n",
    "\n",
    "    return init_tparams(p)\n",
    "\n",
    "\n",
    "def z_to_x(p,z):\n",
    "\n",
    "    print \"no extra noise input\"\n",
    "    z_inp = join2(z, 0.0*srng.normal(size=z.shape))\n",
    "\n",
    "    d0 = fflayer(tparams=p,state_below=z_inp,options={},prefix='z_x_1',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)')\n",
    "\n",
    "    d0 = d0.reshape((64,512,4,4))\n",
    "\n",
    "    d1 = convlayer(tparams=p,state_below=d0,options={},prefix='z_x_2',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)',stride=-2)\n",
    "\n",
    "    d2 = convlayer(tparams=p,state_below=d1,options={},prefix='z_x_3',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)',stride=-2)\n",
    "\n",
    "    d3 = convlayer(tparams=p,state_below=d2,options={},prefix='z_x_4',activ='lambda x: x',stride=-2)\n",
    "\n",
    "    x_new = d3.flatten(2)\n",
    "\n",
    "    return x_new\n",
    "\n",
    "def x_to_z(p,x):\n",
    "\n",
    "    e1 = convlayer(tparams=p,state_below=x.reshape((64,3,32,32)),options={},prefix='x_z_1',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)',stride=1)\n",
    "\n",
    "    e2 = convlayer(tparams=p,state_below=e1,options={},prefix='x_z_2',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)',stride=2)\n",
    "\n",
    "    e3 = convlayer(tparams=p,state_below=e2,options={},prefix='x_z_3',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)',stride=1)\n",
    "\n",
    "    e4 = convlayer(tparams=p,state_below=e3,options={},prefix='x_z_4',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)',stride=2)\n",
    "\n",
    "    e5 = convlayer(tparams=p,state_below=e4,options={},prefix='x_z_5',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)',stride=2)\n",
    "\n",
    "    eo = e5\n",
    "    eo = eo.flatten(2)\n",
    "\n",
    "    encoder_features = eo\n",
    "\n",
    "    h1 = fflayer(tparams=p,state_below=eo,options={},prefix='x_z_fc1',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)')\n",
    "    h2 = fflayer(tparams=p,state_below=h1,options={},prefix='x_z_fc2',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)')\n",
    "\n",
    "    sigma = fflayer(tparams=p,state_below=h2,options={},prefix='x_z_mu',activ='lambda x: x')\n",
    "    mu = fflayer(tparams=p,state_below=h2,options={},prefix='x_z_sigma',activ='lambda x: x')\n",
    "\n",
    "    eps = srng.normal(size=sigma.shape)\n",
    "\n",
    "    z_new = eps*T.nnet.sigmoid(sigma) + mu\n",
    "    print \"turned on injected noise in x->z connection\"\n",
    "\n",
    "    z_new = (z_new - T.mean(z_new, axis=0, keepdims=True)) / (0.001 + T.std(z_new, axis=0, keepdims=True))\n",
    "\n",
    "    return z_new,encoder_features\n",
    "\n",
    "def classifier(p,z,true_y):\n",
    "\n",
    "    print \"turning off gradients from classifier\"\n",
    "    z = consider_constant(z)\n",
    "\n",
    "    h1 = fflayer(tparams=p,state_below=z,options={},prefix='c_1',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)')\n",
    "\n",
    "    h2 = fflayer(tparams=p,state_below=h1,options={},prefix='c_2',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)')\n",
    "\n",
    "    y_est = fflayer(tparams=p,state_below=h2,options={},prefix='c_3',activ='lambda x: x')\n",
    "\n",
    "    y_est = T.nnet.softmax(y_est)\n",
    "\n",
    "    acc = accuracy(y_est,true_y)\n",
    "    loss = crossent(y_est,true_y)\n",
    "\n",
    "    return loss,acc\n",
    "\n",
    "def discriminator(p,x,z):\n",
    "\n",
    "    dc_1 = convlayer(tparams=p,state_below=x.reshape((64,3,32,32)),options={},prefix='DC_1',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)',stride=1)\n",
    "\n",
    "    dc_2 = convlayer(tparams=p,state_below=dc_1,options={},prefix='DC_2',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)',stride=2)\n",
    "\n",
    "    dc_3 = convlayer(tparams=p,state_below=dc_2,options={},prefix='DC_3',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)',stride=1)\n",
    "\n",
    "    dc_4 = convlayer(tparams=p,state_below=dc_3,options={},prefix='DC_4',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)',stride=2)\n",
    "\n",
    "    dc_5 = convlayer(tparams=p,state_below=dc_4,options={},prefix='DC_5',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)',stride=2)\n",
    "\n",
    "    inp = join2(z,dc_5.flatten(2))\n",
    "\n",
    "    h1 = fflayer(tparams=p,state_below=inp,options={},prefix='D_1',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)',mean_ln=False)\n",
    "\n",
    "    h2 = fflayer(tparams=p,state_below=h1,options={},prefix='D_2',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)', mean_ln=False)\n",
    "\n",
    "    h3 = fflayer(tparams=p,state_below=h2,options={},prefix='D_3',activ='lambda x: tensor.nnet.relu(x,alpha=0.02)', mean_ln=False)\n",
    "\n",
    "    D1 = fflayer(tparams=p,state_below=h1,options={},prefix='D_o_1',activ='lambda x: x')\n",
    "    D2 = fflayer(tparams=p,state_below=h2,options={},prefix='D_o_2',activ='lambda x: x')\n",
    "    D3 = fflayer(tparams=p,state_below=h3,options={},prefix='D_o_3',activ='lambda x: x')\n",
    "\n",
    "    D4 = convlayer(tparams=p,state_below=dc_3,options={},prefix='D_o_4',activ='lambda x: x',stride=2)\n",
    "    D5 = convlayer(tparams=p,state_below=dc_4,options={},prefix='D_o_5',activ='lambda x: x',stride=2)\n",
    "    D6 = convlayer(tparams=p,state_below=dc_5,options={},prefix='D_o_6',activ='lambda x: x',stride=2)\n",
    "\n",
    "    print \"special thing in D\"\n",
    "    return [D1,D2,D3,D4,D5,D6], [h3,dc_5.flatten(2)]\n",
    "\n",
    "def p_chain(p, z, num_iterations):\n",
    "    zlst = [z]\n",
    "    xlst = []\n",
    "\n",
    "    if num_iterations == 1:\n",
    "        \n",
    "        new_x = z_to_x(p, zlst[-1])\n",
    "        xlst.append(new_x)\n",
    "        #new_z = x_to_z(p, xlst[-1])\n",
    "        #zlst.append(new_z)\n",
    "\n",
    "    elif num_iterations == 3:  \n",
    "\n",
    "        new_x = z_to_x(p, zlst[-1])\n",
    "        xlst.append(new_x)\n",
    "        new_z,_ = x_to_z(p, consider_constant(xlst[-1]))\n",
    "        zlst.append(new_z)\n",
    "\n",
    "        new_x = z_to_x(p, zlst[-1])\n",
    "        xlst.append(new_x)\n",
    "        new_z,_ = x_to_z(p, consider_constant(xlst[-1]))\n",
    "        zlst.append(new_z)\n",
    "\n",
    "        new_x = z_to_x(p, zlst[-1])\n",
    "        xlst.append(new_x)\n",
    "\n",
    "    else:\n",
    "\n",
    "        for inds in range(0,num_iterations):\n",
    "            new_x = z_to_x(p, zlst[-1])\n",
    "            xlst.append(new_x)\n",
    "            new_z,_ = x_to_z(p, xlst[-1])\n",
    "            zlst.append(new_z)\n",
    "\n",
    "\n",
    "    for j in range(len(xlst)):\n",
    "        xlst[j] = T.nnet.sigmoid(xlst[j])\n",
    "\n",
    "    return xlst, zlst\n",
    "\n",
    "def onestep_z_to_x(p,z):\n",
    "    x = T.nnet.sigmoid(z_to_x(p, z))\n",
    "    return x\n",
    "\n",
    "def onestep_x_to_z(p,x):\n",
    "    new_z,_ = x_to_z(p, inverse_sigmoid(x))\n",
    "    return new_z\n",
    "\n",
    "def q_chain(p,x,num_iterations):\n",
    "\n",
    "    xlst = [x]\n",
    "    zlst = []\n",
    "    new_z,encoder_features = x_to_z(p, inverse_sigmoid(xlst[-1]))\n",
    "    zlst.append(new_z)\n",
    "\n",
    "    return xlst, zlst,encoder_features\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "print \"a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle, os\n",
    "\n",
    "directory = \"/Tmp/cohenjos/\"\n",
    "ext = \"svhn-soa-svm.p\"\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    \n",
    "def save_network(gparams,dparams, cparams,name):\n",
    "    pkl_params = (gparams,dparams, cparams)\n",
    "    out = open(directory + str(name) + ext, \"w\", 0) #bufsize=0\n",
    "    pickle.dump(pkl_params, out)\n",
    "    out.close()\n",
    "\n",
    "def load_network(name):\n",
    "    return pickle.load(open(directory + str(name) + ext, \"r\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gparams,dparams, cparams = load_network(\"base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gparams = init_gparams({})\n",
    "# dparams = init_dparams({})\n",
    "# cparams = init_cparams({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num latent 128\n",
      "num steps 3\n",
      "latent sparse False\n",
      "improvement loss weight 0.0\n",
      "num labeled examples used 50000\n",
      "dataset svhn\n",
      "num train examples 604388\n",
      "num test examples 26032\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "no extra noise input\n",
      "turned on injected noise in x->z connection\n",
      "special thing in D\n",
      "single disc\n",
      "special thing in D\n",
      "turning off gradients from classifier\n",
      "not using improvement objective\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Refreshing lock /tmp/cohenjos/theano.NOBACKUP/compiledir_Linux-3.16--amd64-x86_64-with-debian-8.8--2.7.13-64/lock_dir/lock\n",
      "INFO (theano.gof.compilelock): Refreshing lock /tmp/cohenjos/theano.NOBACKUP/compiledir_Linux-3.16--amd64-x86_64-with-debian-8.8--2.7.13-64/lock_dir/lock\n",
      "INFO (theano.gof.compilelock): Refreshing lock /tmp/cohenjos/theano.NOBACKUP/compiledir_Linux-3.16--amd64-x86_64-with-debian-8.8--2.7.13-64/lock_dir/lock\n",
      "INFO (theano.gof.compilelock): Refreshing lock /tmp/cohenjos/theano.NOBACKUP/compiledir_Linux-3.16--amd64-x86_64-with-debian-8.8--2.7.13-64/lock_dir/lock\n",
      "INFO (theano.gof.compilelock): Refreshing lock /tmp/cohenjos/theano.NOBACKUP/compiledir_Linux-3.16--amd64-x86_64-with-debian-8.8--2.7.13-64/lock_dir/lock\n"
     ]
    }
   ],
   "source": [
    "nl = 128\n",
    "print \"num latent\", nl\n",
    "#128 works for nl\n",
    "nfg = 512\n",
    "nfd = 512\n",
    "\n",
    "\n",
    "#3\n",
    "num_steps = 3\n",
    "print \"num steps\", num_steps\n",
    "\n",
    "latent_sparse = False\n",
    "print \"latent sparse\", latent_sparse\n",
    "\n",
    "improvement_loss_weight = 0.0\n",
    "print \"improvement loss weight\", improvement_loss_weight\n",
    "\n",
    "num_labeled_examples_use = 50000\n",
    "print \"num labeled examples used\",num_labeled_examples_use\n",
    "\n",
    "#dataset = \"mnist\"\n",
    "#dataset = \"anime\"\n",
    "dataset = \"svhn\"\n",
    "print \"dataset\", dataset\n",
    "\n",
    "if dataset == \"mnist\":\n",
    "    mn = gzip.open(\"/u/lambalex/data/mnist/mnist.pkl.gz\")\n",
    "\n",
    "    train, valid, test = pickle.load(mn)\n",
    "\n",
    "    trainx,trainy = train\n",
    "\n",
    "\n",
    "    #newtx = trainx[(trainy<2) | (trainy>8)]\n",
    "    #newty = trainy[(trainy<2) | (trainy>8)]\n",
    "    #trainx = newtx\n",
    "    #trainy = newty\n",
    "\n",
    "    validx,validy = valid\n",
    "    testx, testy = test\n",
    "\n",
    "    num_examples = trainx.shape[0]\n",
    "\n",
    "    m = 784\n",
    "\n",
    "elif dataset == \"anime\":\n",
    "    from load_file import FileData, normalize, denormalize\n",
    "\n",
    "    loc = \"/u/lambalex/DeepLearning/animefaces/datafaces/danbooru-faces/\"\n",
    "\n",
    "    animeData = FileData(loc, 32, 64)\n",
    "\n",
    "    m = 32*32*3\n",
    "\n",
    "elif dataset == \"svhn\":\n",
    "\n",
    "    from load_svhn import SvhnData\n",
    "    from load_file import normalize, denormalize\n",
    "\n",
    "    svhnData = SvhnData()\n",
    "\n",
    "    num_examples = 50000\n",
    "\n",
    "\n",
    "\n",
    "z_in = T.matrix('z_in')\n",
    "x_in = T.matrix()\n",
    "true_y = T.ivector('true_y')\n",
    "\n",
    "p_lst_x,p_lst_z = p_chain(gparams, z_in, num_steps)\n",
    "\n",
    "q_lst_x,q_lst_z,encoder_features = q_chain(gparams, x_in, num_steps)\n",
    "\n",
    "p_lst_x_long,p_lst_z_long = p_chain(gparams, z_in, 19)\n",
    "\n",
    "z_inf = q_lst_z[-1]\n",
    "\n",
    "D_p_lst_1,_ = discriminator(dparams, p_lst_x[-1], p_lst_z[-1])\n",
    "\n",
    "if False:\n",
    "    D_p_lst_2,_ = discriminator(dparams, p_lst_x[-2], p_lst_z[-2])\n",
    "    D_p_lst = D_p_lst_1 + D_p_lst_2\n",
    "    print \"double disc\"\n",
    "else:\n",
    "    D_p_lst = D_p_lst_1\n",
    "    print \"single disc\"\n",
    "\n",
    "D_q_lst,D_feat_q = discriminator(dparams, q_lst_x[-1], q_lst_z[-1])\n",
    "\n",
    "closs,cacc = classifier(cparams,join2(z_inf,encoder_features),true_y)\n",
    "\n",
    "dloss, gloss = lsgan_loss(D_q_lst, D_p_lst)\n",
    "\n",
    "print \"not using improvement objective\"\n",
    "#improvement_objective = improvement_loss_weight * improvement_loss(D_p_lst_1, D_p_lst_2)\n",
    "#gloss += improvement_objective\n",
    "\n",
    "dupdates = lasagne.updates.rmsprop(dloss, dparams.values(),0.0001)\n",
    "gloss_grads = T.grad(gloss, gparams.values(), disconnected_inputs='ignore')\n",
    "gupdates = lasagne.updates.rmsprop(gloss_grads, gparams.values(),0.0001)\n",
    "\n",
    "gcupdates = lasagne.updates.rmsprop(gloss + closs, gparams.values() + cparams.values(),0.0001)\n",
    "dcupdates = lasagne.updates.rmsprop(dloss + closs, dparams.values() + cparams.values(),0.0001)\n",
    "\n",
    "dgupdates = dupdates.copy()\n",
    "dgupdates.update(gupdates)\n",
    "\n",
    "dgcupdates = dcupdates.copy()\n",
    "dgcupdates.update(gcupdates)\n",
    "\n",
    "train_disc_gen_classifier = theano.function(inputs = [x_in, z_in,true_y], outputs=[dloss,p_lst_x[-1],p_lst_z[-1],closs,cacc], updates=dgcupdates,on_unused_input='ignore')\n",
    "\n",
    "train_disc_gen = theano.function(inputs = [x_in, z_in], outputs=[dloss,p_lst_x[-1],p_lst_z[-1]], updates=dgupdates,on_unused_input='ignore')\n",
    "\n",
    "train_disc_gen_faster = theano.function(inputs = [x_in, z_in], outputs=dloss, updates=dgupdates,on_unused_input='ignore')\n",
    "\n",
    "test_classifier = theano.function(inputs = [x_in,true_y], outputs=[closs,cacc],on_unused_input='ignore')\n",
    "\n",
    "get_zinf = theano.function([x_in], outputs=z_inf)\n",
    "#get_dfeat = theano.function([x_in], outputs=D_feat_q)\n",
    "\n",
    "#get_pchain = theano.function([z_in], outputs = p_lst_x_long)\n",
    "\n",
    "x_in = T.matrix()\n",
    "\n",
    "func_z_to_x = theano.function([z_in], outputs = onestep_z_to_x(gparams, z_in))\n",
    "func_x_to_z = theano.function([x_in], outputs = onestep_x_to_z(gparams, x_in))\n",
    "\n",
    "z_out_p = rng.normal(size=(64,nl)).astype('float32')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_x = T.matrix('x')\n",
    "\n",
    "z_inf,z_feat = x_to_z(gparams, inverse_sigmoid(input_x))\n",
    "\n",
    "d_val, d_feat = discriminator(dparams, input_x, z_inf)\n",
    "\n",
    "#z_feat, d_feat[1]\n",
    "get_dz = theano.function([input_x], outputs = [d_feat[0],d_feat[1]])\n",
    "\n",
    "get_z = func_x_to_z\n",
    "\n",
    "\n",
    "#rec = theano.function([input_x], outputs = [T.nnet.sigmoid(z_to_x(gparams,x_to_z(gparams,inverse_sigmoid(input_x))[0]))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get_dz(x)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ud = pickle.load(open(\"stats2.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# zstats = []\n",
    "# dzstats = []\n",
    "zstats = ud[1]\n",
    "dzstats = ud[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for iteration in range(0,500000):\n",
    "\n",
    "    z_in2 = rng.normal(size=(64,nl)).astype('float32')\n",
    "\n",
    "    if latent_sparse:\n",
    "        z_in2[:,128:] *= 0.0\n",
    "\n",
    "    r = random.randint(0,num_examples-64)\n",
    "\n",
    "    if dataset == \"mnist\":\n",
    "        x_in = trainx[r:r+64]\n",
    "        y_in = trainy[r:r+64]\n",
    "\n",
    "        x_in = x_in.reshape((64,1,28,28))\n",
    "\n",
    "        x_in = np.repeat(x_in,3,axis=(1))\n",
    "        x_in = np.lib.pad(x_in,((0,0),(0,0),(2,2),(2,2)),'constant',constant_values=(0))\n",
    "\n",
    "        x_in = x_in.reshape((64,32*32*3))\n",
    "    elif dataset == \"anime\":\n",
    "        x_in = normalize(animeData.getBatch()).reshape((64,32*32*3))\n",
    "\n",
    "    elif dataset == \"svhn\":\n",
    "\n",
    "        #just do a quick update using the whole thing.  \n",
    "\n",
    "        ind = random.randint(0,574168-64)\n",
    "        svhn_batch = svhnData.getBatch(mb_size=64,index=ind,segment=\"train\")\n",
    "        x_in2 = normalize(svhn_batch['x']).reshape((64,32*32*3))\n",
    "        train_disc_gen_faster(x_in2,z_in2)\n",
    "\n",
    "        if random.uniform(0,1) < 0.1:\n",
    "            ind = random.randint(0,num_labeled_examples_use)\n",
    "            svhn_batch = svhnData.getBatch(mb_size=64,index=ind,segment=\"hard_train\")\n",
    "            x_in2 = normalize(svhn_batch['x']).reshape((64,32*32*3))\n",
    "            y_in = svhn_batch['y']\n",
    "\n",
    "            dloss,gen_x,z_out_p,closs,cacc = train_disc_gen_classifier(x_in2,z_in2,y_in)\n",
    "\n",
    "            print \"i\", iteration, \"dloss\", dloss, \"gen_x mean\", gen_x.mean(), \"closs\", closs, \"cacc\", cacc\n",
    "\n",
    "    if iteration % 1000 == 0:\n",
    "\n",
    "        if dataset == \"svhn\":\n",
    "            acclst = []\n",
    "            for ind in range(0,26032-128,64):\n",
    "            #ind = random.randint(0,26032-64)\n",
    "                testbatch = svhnData.getBatch(index=ind,mb_size=64,segment=\"test\")\n",
    "                closs,cacc = test_classifier(normalize(testbatch['x']).reshape((64,32*32*3)),testbatch['y'])\n",
    "                acclst.append(cacc)\n",
    "\n",
    "            print \"all test data\"\n",
    "            print \"test accuracy\", sum(acclst)*1.0/len(acclst)\n",
    "\n",
    "        #######plot_images(gen_x, \"plots/\" + slurm_name + \"_gen.png\")\n",
    "        plot_images(func_z_to_x(func_x_to_z(x_in2)).reshape((64,32*32*3)), \"plots/\" + slurm_name + \"_rec.png\")\n",
    "\n",
    "\n",
    "\n",
    "        dhlst = []\n",
    "        dzhlst = []\n",
    "        ylst = []\n",
    "        t0 = time.time()\n",
    "\n",
    "        dhlst_test = []\n",
    "        dzhlst_test = []\n",
    "        ylst_test = []\n",
    "\n",
    "        print \"all train set\"\n",
    "#         print \"only using eoz features\"\n",
    "\n",
    "        for ind in range(0,1000,64):\n",
    "\n",
    "            svhn_batch = svhnData.getBatch(mb_size=64,index=ind,segment=\"train\")\n",
    "            x = normalize(svhn_batch['x']).reshape((64,3*32*32))\n",
    "            y = svhn_batch['y']\n",
    "\n",
    "            zstuff = get_z(x)\n",
    "            dzstuff = get_dz(x)\n",
    "\n",
    "            #print zstuff[0].shape, zstuff[1].shape, zstuff[2].shape\n",
    "            dhlst.append(zstuff)\n",
    "            dzhlst.append(np.concatenate(dzstuff,axis=1))\n",
    "            \n",
    "            ylst.append(y)\n",
    "\n",
    "        for ind in range(0,20000,64):\n",
    "            svhn_batch = svhnData.getBatch(mb_size=64,index=ind,segment=\"test\")\n",
    "            x = normalize(svhn_batch['x']).reshape((64,3*32*32))\n",
    "            y = svhn_batch['y']\n",
    "            zstuff = get_z(x)\n",
    "            dzstuff = get_dz(x)\n",
    "            \n",
    "            dhlst_test.append(zstuff)\n",
    "            dzhlst_test.append(np.concatenate(dzstuff,axis=1))\n",
    "            \n",
    "            ylst_test.append(y)\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "        ##### DDDDDDZZZZZZZ\n",
    "        X_train = np.vstack(dzhlst)\n",
    "        Y_train = np.vstack(ylst).flatten()\n",
    "\n",
    "        X_test = np.vstack(dzhlst_test)\n",
    "        Y_test = np.vstack(ylst_test).flatten()\n",
    "\n",
    "        \n",
    "        C = 1.0\n",
    "        print \"DDDDDDZZZZZZZ starting training!\", \"using svm linear\", \"C\", C, \"squared hinge\"\n",
    "\n",
    "        model = svm.LinearSVC(C=C,loss='squared_hinge')\n",
    "\n",
    "        model.fit(X_train, Y_train)\n",
    "\n",
    "        print \"predicting held out\"\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        testacc = np.mean(np.equal(Y_test, y_pred))\n",
    "        #print \"held out accuracy\", testacc\n",
    "\n",
    "        y_pred = model.predict(X_train)\n",
    "\n",
    "        trainacc = np.mean(np.equal(Y_train, y_pred))\n",
    "        #print \"training accuracy\", trainacc\n",
    "\n",
    "        #print time.time() - t0, \"total time to run\"\n",
    "        \n",
    "        print \"###d#\",iteration, \"testacc\", testacc, \"trainacc\", trainacc\n",
    "        zstats.append([testacc, trainacc])\n",
    "        \n",
    "        \n",
    "        \n",
    "        ##### ZZZZZZZ\n",
    "        \n",
    "        X_train = np.vstack(dhlst)\n",
    "        Y_train = np.vstack(ylst).flatten()\n",
    "\n",
    "        X_test = np.vstack(dhlst_test)\n",
    "        Y_test = np.vstack(ylst_test).flatten()\n",
    "\n",
    "\n",
    "        C = 1.0\n",
    "        print \"ZZZZZZ starting training!\", \"using svm linear\", \"C\", C, \"squared hinge\"\n",
    "\n",
    "        model = svm.LinearSVC(C=C,loss='squared_hinge')\n",
    "\n",
    "        model.fit(X_train, Y_train)\n",
    "\n",
    "        print \"predicting held out\"\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        testacc = np.mean(np.equal(Y_test, y_pred))\n",
    "        #print \"held out accuracy\", testacc\n",
    "\n",
    "        y_pred = model.predict(X_train)\n",
    "\n",
    "        trainacc = np.mean(np.equal(Y_train, y_pred))\n",
    "        #print \"training accuracy\", trainacc\n",
    "\n",
    "        \n",
    "        print \"###dz#\",iteration, \"testacc\", testacc, \"trainacc\", trainacc\n",
    "        dzstats.append([testacc, trainacc])\n",
    "        \n",
    "        statsname = \"stats22.pkl\"\n",
    "        print \"writing\", statsname, time.time() - t0, \"total time to run\"\n",
    "\n",
    "        pickle.dump([zstats,dzstats], open(statsname, \"w\", 0))\n",
    "        \n",
    "        paramsfile = str(iteration) + \"baseparamsfile2\"\n",
    "        print \"writing\",paramsfile\n",
    "        save_network(gparams,dparams, cparams,paramsfile)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_network(gparams,dparams, cparams,\"base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7facc4d53fd0>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7facc9922690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.asarray(dzstats)[:,1], label=\"Gen Train\", linestyle='-', c=\"blue\")\n",
    "plt.plot(np.asarray(dzstats)[:,0], label=\"Gen Test\", linestyle='--', c=\"blue\")\n",
    "\n",
    "plt.plot(np.asarray(zstats)[:,1], label=\"Disc Train\", linestyle='-', c=\"red\")\n",
    "plt.plot(np.asarray(zstats)[:,0], label=\"Disc Test\", linestyle='--', c=\"red\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "from fuel.converters.base import fill_hdf5_file\n",
    "from fuel.datasets import SVHN\n",
    "from fuel.streams import DataStream\n",
    "from fuel.schemes import SequentialScheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25984"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "64*406"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01499099, -0.03380182, -0.03078402, ..., -0.00688451,\n",
       "        -0.01278257, -0.01968044],\n",
       "       [-0.01733678, -0.03521392, -0.03306841, ..., -0.00302404,\n",
       "        -0.01493562, -0.02645339],\n",
       "       [-0.02067768, -0.0294    , -0.03129628, ..., -0.0003717 ,\n",
       "        -0.02106036, -0.02181587],\n",
       "       ..., \n",
       "       [-0.0163266 , -0.03312733, -0.034986  , ..., -0.00940088,\n",
       "        -0.03095791, -0.02540156],\n",
       "       [-0.01599311, -0.03785766, -0.03534985, ..., -0.00645354,\n",
       "        -0.02583494, -0.02205506],\n",
       "       [-0.01648992, -0.03358139, -0.03400288, ..., -0.01057131,\n",
       "        -0.00384989, -0.02460445]], dtype=float32)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(*train_stream.get_epoch_iterator().next())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turned on injected noise in x->z connection\n",
      "special thing in D\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_x = T.matrix('x')\n",
    "input_y = T.imatrix('targets')\n",
    "\n",
    "\n",
    "z_inf,z_feat = x_to_z(gparams, inverse_sigmoid(input_x))\n",
    "\n",
    "d_val, d_feat = discriminator(dparams, input_x, z_inf)\n",
    "\n",
    "#get_dz = theano.function([input_x], outputs = [d_feat[0],d_feat[1]])\n",
    "\n",
    "#preprocess = theano.function([x, y], [output.flatten(ndim=2), y])\n",
    "\n",
    "\n",
    "#disc\n",
    "#prepreprocess = theano.function([input_x, input_y], outputs = [T.concatenate([d_feat[0],d_feat[1]], axis=1),input_y])\n",
    "\n",
    "#disc0\n",
    "#prepreprocess = theano.function([input_x, input_y], outputs = [d_feat[0],input_y])\n",
    "\n",
    "#z\n",
    "#prepreprocess = theano.function([input_x, input_y], outputs = [z_inf,input_y])\n",
    "\n",
    "#z2\n",
    "#prepreprocess = theano.function([input_x, input_y], outputs = [z_feat,input_y])\n",
    "\n",
    "\n",
    "#all\n",
    "prepreprocess = theano.function([input_x, input_y], outputs = \n",
    "                               [T.concatenate([d_feat[0],d_feat[1], z_inf, z_feat], axis=1),input_y])\n",
    "\n",
    "#both\n",
    "prepreprocess = theano.function([input_x, input_y], outputs = \n",
    "                               [T.concatenate([d_feat[0],d_feat[1], z_inf, z_feat], axis=1),input_y])\n",
    "\n",
    "\n",
    "\n",
    "# def preprocess(x,y):\n",
    "#     return prepreprocess(normalize(x).reshape((-1,32*32*3)),y)\n",
    "\n",
    "def preprocess(x,y):\n",
    "    return prepreprocess(x.reshape((-1,32*32*3)),y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_stream.get_epoch_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#preprocess(*train_stream.get_epoch_iterator().next())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#preprocess2(*train_stream.get_epoch_iterator().next())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data\n",
      "test data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "h5file = h5py.File(\"/Tmp/cohenjos/ALI-semisuper-allall\", mode='w')\n",
    "\n",
    "print \"train data\"\n",
    "train_set = SVHN(2, which_sets=('train',), sources=('features', 'targets'))\n",
    "train_stream = DataStream.default_stream(\n",
    "    train_set,\n",
    "    iteration_scheme=SequentialScheme(73216, 64))\n",
    "train_features, train_targets = map(\n",
    "    np.vstack,\n",
    "    list(zip(*[preprocess(*batch) for batch in\n",
    "               train_stream.get_epoch_iterator()])))\n",
    "\n",
    "print \"test data\"\n",
    "test_set = SVHN(2, which_sets=('test',), sources=('features', 'targets'))\n",
    "test_stream = DataStream.default_stream(\n",
    "    test_set,\n",
    "    iteration_scheme=SequentialScheme(25984, 64))\n",
    "test_features, test_targets = map(\n",
    "    np.vstack,\n",
    "    list(zip(*[preprocess(*batch) for batch in\n",
    "               test_stream.get_epoch_iterator()])))\n",
    "\n",
    "data = (('train', 'features', train_features),\n",
    "        ('test', 'features', test_features),\n",
    "        ('train', 'targets', train_targets),\n",
    "        ('test', 'targets', test_targets))\n",
    "fill_hdf5_file(h5file, data)\n",
    "for i, label in enumerate(('batch', 'feature')):\n",
    "    h5file['features'].dims[i].label = label\n",
    "for i, label in enumerate(('batch', 'index')):\n",
    "    h5file['targets'].dims[i].label = label\n",
    "\n",
    "h5file.flush()\n",
    "h5file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5file.flush()\n",
    "h5file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25984, 8192)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25984, 1)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[3][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
